{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587fdcb3-05d4-40f3-ad03-72c76ba754ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "txt_files = [\n",
    "    \"Alan_Weisman conv.txt\",\n",
    "    \"Aldo Leopold conv.txt\",\n",
    "    \"Amy Godine conv.txt\",\n",
    "    \"Anne_Therese_Gennari conv.txt\",\n",
    "    \"Barbara_Kingsolver conv.txt\",\n",
    "    \"Bill_Mckibben conv.txt\",\n",
    "    \"Camille_T_Dungy conv.txt\",\n",
    "    \"Carolyn Merchant conv.txt\",\n",
    "    \"David_Goulson conv.txt\",\n",
    "    \"Dina_Gilio_Whitaker conv.txt\",\n",
    "    \"Dr_Seuss conv.txt\",\n",
    "    \"Greta_Thunberg conv.txt\",\n",
    "    \"Jane_Goodall conv.txt\",\n",
    "    \"Jon_Krakauer conv.txt\",\n",
    "    \"Peter_Wohlleben conv.txt\",\n",
    "    \"Rachel_Carson conv.txt\",\n",
    "    \"Richard_Powers conv.txt\",\n",
    "    \"Val_Plumwood conv.txt\",\n",
    "    \"_OceanofPDF.com_Braiding_Sweetgrass_-_Robin_Wall_Kimmerer conv.txt\"\n",
    "]\n",
    "\n",
    "guten_dict = {\n",
    "    \"https://www.gutenberg.org/files/17748/17748-h/17748-h.htm\": {\n",
    "        \"title\": \"The Extermination of the American Bison\",\n",
    "        \"author\": \"William T. Hornaday\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/files/205/205-h/205-h.htm\": {\n",
    "        \"title\": \"Walden\", \n",
    "        \"author\": \"Henry David Thoreau\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/49270/pg49270-images.html\": {\n",
    "        \"title\": \"African Nature Notes and Reminiscences\",\n",
    "        \"author\": \"Frederick Courteney Selous\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/66546/pg66546-images.html\": {\n",
    "        \"title\": \"The Ivory King: A Popular History of the Elephant and Its Allies\",\n",
    "        \"author\": \"Charles Fredrick Holde\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/ebooks/73563\": {\n",
    "        \"title\": \"Tropical Nature, and Other Essays\", \n",
    "        \"author\": \"Alfred Russel Wallace\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/44764/pg44764-images.html\": {\n",
    "        \"title\": \"California: The Land of the Sun\",\n",
    "        \"author\": \"Mary Austin\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "author_genders = {\n",
    "    # Local file authors\n",
    "    \"Alan_Weisman\": \"M\",\n",
    "    \"Aldo Leopold\": \"M\", \n",
    "    \"Amy Godine\": \"F\",\n",
    "    \"Anne_Therese_Gennari\": \"F\",\n",
    "    \"Barbara_Kingsolver\": \"F\",\n",
    "    \"Bill_Mckibben\": \"M\",\n",
    "    \"Camille_T_Dungy\": \"F\", \n",
    "    \"Carolyn Merchant\": \"F\",\n",
    "    \"David_Goulson\": \"M\",\n",
    "    \"Dina_Gilio_Whitaker\": \"F\",\n",
    "    \"Dr_Seuss\": \"M\",\n",
    "    \"Greta_Thunberg\": \"F\",\n",
    "    \"Jane_Goodall\": \"F\",\n",
    "    \"Jon_Krakauer\": \"M\",\n",
    "    \"Peter_Wohlleben\": \"M\",\n",
    "    \"Rachel_Carson\": \"F\",\n",
    "    \"Richard_Powers\": \"M\",\n",
    "    \"Val_Plumwood\": \"F\",\n",
    "    \"_Robin_Wall_Kimmerer\": \"F\",\n",
    "    \n",
    "    # Gutenberg authors\n",
    "    \"William T. Hornaday\": \"M\",\n",
    "    \"Henry David Thoreau\": \"M\",\n",
    "    \"Frederick Courteney Selous\": \"M\", \n",
    "    \"Charles Fredrick Holde\": \"M\",\n",
    "    \"Alfred Russel Wallace\": \"M\",\n",
    "    \"Mary Austin\": \"F\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f58209-221f-4b0c-9f91-ca58891deee1",
   "metadata": {},
   "source": [
    "Gutenberg Cleaner:\n",
    "\n",
    "https://github.com/kiasar/gutenberg_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f095b61-fe0c-4176-a9ae-e1b7a11d3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gutenberg_cleaner in /opt/anaconda3/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from gutenberg_cleaner) (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gutenberg_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551e9ea1-5438-4d17-bd57-4f204b999997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenberg_cleaner import simple_cleaner, super_cleaner\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d855c8-e3c0-4857-b0ef-c6bd609aed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Aldo Leopold conv.txt: only 1 words after filtering\n",
      "Skipping Bill_Mckibben conv.txt: only 1 words after filtering\n",
      "Skipping Carolyn Merchant conv.txt: only 0 words after filtering\n",
      "Skipping Dr_Seuss conv.txt: only 1 words after filtering\n",
      "Skipping Jon_Krakauer conv.txt: only 1 words after filtering\n",
      "Skipping Peter_Wohlleben conv.txt: only 1 words after filtering\n",
      "Skipping Richard_Powers conv.txt: only 1 words after filtering\n",
      "Skipping The Extermination of the American Bison: only 0 words after filtering\n",
      "Skipping The Ivory King: A Popular History of the Elephant and Its Allies: only 0 words after filtering\n",
      "Skipping California: The Land of the Sun: only 0 words after filtering\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store final results\n",
    "final_dictionary = {}\n",
    "\n",
    "# Process local files \n",
    "for text_file in txt_files:\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Use simple_cleaner local files, might be too harsh for local girlies but we'll see\n",
    "    filtered_content = simple_cleaner(content)\n",
    "    \n",
    "    words = filtered_content.split()\n",
    "    # Skip files with 0 or 1 words after filtering\n",
    "    if len(words) <= 1:\n",
    "        print(f\"Skipping {text_file}: only {len(words)} words after filtering\")\n",
    "        continue\n",
    "\n",
    "    if len(words) > 5000:\n",
    "        start_index = np.random.randint(0, len(words) - 5000)\n",
    "        text_selection = words[start_index:start_index + 5000]\n",
    "    else:\n",
    "        text_selection = words\n",
    "\n",
    "    author_name = text_file.split(\" conv.txt\")[0]\n",
    "    gender = author_genders.get(author_name, \"Unknown\")\n",
    "\n",
    "    final_dictionary[author_name] = {\n",
    "        \"title\": text_file.replace(\" conv.txt\", \"\"),\n",
    "        \"author\": author_name,\n",
    "        \"words\": text_selection,\n",
    "        \"gender\": gender,\n",
    "        \"word_count\": len(text_selection)\n",
    "    }\n",
    "\n",
    "# Process Gutenberg books\n",
    "for url, meta in guten_dict.items():\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    html = resp.text\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag in soup(['script', 'style', 'header', 'footer', 'nav']):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    clean_text = \" \".join(text.split())\n",
    "\n",
    "    # Just removes lines that are part of the Project Gutenberg header or footer\n",
    "    # Doesnt go deeply in the text to remove other things like titles or footnotes or etc\n",
    "    # return: str of the book without the lines that are part of the Project Gutenberg header and footer\n",
    "    cleaned_text = simple_cleaner(clean_text)  # Basic cleaning\n",
    "    # OR for more aggressive cleaning:\n",
    "    # cleaned_text = super_cleaner(clean_text, min_token=10, max_token=500)\n",
    "    \n",
    "    words = cleaned_text.split()\n",
    "\n",
    "    # Skip files with 0 or 1 words after filtering\n",
    "    if len(words) <= 1:\n",
    "        print(f\"Skipping {meta['title']}: only {len(words)} words after filtering\")\n",
    "        continue\n",
    "\n",
    "    if len(words) >= 5000:\n",
    "        start_index = np.random.randint(0, len(words) - 5000)\n",
    "        text_selection = words[start_index:start_index + 5000]\n",
    "    else:\n",
    "        text_selection = words\n",
    "\n",
    "    author_name = meta[\"author\"]\n",
    "    gender = author_genders.get(author_name, \"Unknown\")\n",
    "\n",
    "    final_dictionary[author_name] = {\n",
    "        \"title\": meta[\"title\"],\n",
    "        \"author\": author_name,\n",
    "        \"words\": text_selection,\n",
    "        \"gender\": gender,\n",
    "        \"word_count\": len(text_selection)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c168400d-c7b9-4d56-9b33-7d4b4920781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors after processing: 15\n",
      "Valid male authors: 5, Valid female authors: 9\n",
      "Total authors in balanced dataset: 10\n",
      "Male authors: 5, Female authors: 5\n",
      "Final balanced dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total authors after processing: {len(final_dictionary)}\")\n",
    "\n",
    "# Balance genders - only include authors with word_count > 1\n",
    "valid_authors = {author: data for author, data in final_dictionary.items() if data['word_count'] > 1}\n",
    "\n",
    "male_authors = [author for author, data in valid_authors.items() if data['gender'] == 'M']\n",
    "female_authors = [author for author, data in valid_authors.items() if data['gender'] == 'F']\n",
    "\n",
    "print(f\"Valid male authors: {len(male_authors)}, Valid female authors: {len(female_authors)}\")\n",
    "\n",
    "if len(male_authors) == 0 or len(female_authors) == 0:\n",
    "    print(\"Warning: Not enough authors of one gender to create balanced dataset\")\n",
    "    balanced_data = valid_authors\n",
    "else:\n",
    "    min_count = min(len(male_authors), len(female_authors))\n",
    "\n",
    "    balanced_male = np.random.choice(male_authors, min_count, replace=False)\n",
    "    balanced_female = np.random.choice(female_authors, min_count, replace=False)\n",
    "\n",
    "    balanced_authors = list(balanced_male) + list(balanced_female)\n",
    "    balanced_data = {author: valid_authors[author] for author in balanced_authors}\n",
    "\n",
    "    print(f\"Total authors in balanced dataset: {len(balanced_data)}\")\n",
    "    print(f\"Male authors: {len(balanced_male)}, Female authors: {len(balanced_female)}\")\n",
    "\n",
    "# Final check - remove any authors with 0 or 1 words from balanced_data (just to be safe)\n",
    "final_balanced_data = {author: data for author, data in balanced_data.items() if data['word_count'] > 1}\n",
    "print(f\"Final balanced dataset size: {len(final_balanced_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55ebc91-4fdb-4434-b31e-b75a8a5c0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "David_Goulson - First 10 words:\n",
      "per cent. They are specialist predators of large, hairy caterpillars\n",
      "\n",
      "Walden - First 10 words:\n",
      "taken up their march, with faint wiry peep, single file\n",
      "\n",
      "Tropical Nature, and Other Essays - First 10 words:\n",
      "Tropical nature, and other essays by Alfred Russel Wallace |\n",
      "\n",
      "Alan_Weisman - First 10 words:\n",
      "decades and erupted viciously several times during the 1950s. A\n",
      "\n",
      "African Nature Notes and Reminiscences - First 10 words:\n",
      "had struck the little Creature on the Loins and broken\n",
      "\n",
      "Dina_Gilio_Whitaker - First 10 words:\n",
      "https://newsmaven.io/indiancountrytoday/archive/northern-cheyenne-sue-to-block-coal-mining-on-public-lands-hPtxUVh1_0GncLXXPSQ9MA. 32. Michelle Tolson, “Yakama Nation Fights for Nuclear Waste\n",
      "\n",
      "Val_Plumwood - First 10 words:\n",
      "beyond this and can never be food. Domination emerges in\n",
      "\n",
      "Jane_Goodall - First 10 words:\n",
      "get to park headquarters on the other side. We could\n",
      "\n",
      "Amy Godine - First 10 words:\n",
      "light, much too focused on the cold to marvel at\n",
      "\n",
      "Greta_Thunberg - First 10 words:\n",
      "or we don’t. Either we go on as a civilization,\n"
     ]
    }
   ],
   "source": [
    "for author_name, author_data in final_balanced_data.items():\n",
    "    words = author_data['words']\n",
    "    title = author_data['title']\n",
    "    \n",
    "    # Print first 10 words to see what's getting through\n",
    "    print(f\"\\n{title} - First 10 words:\")\n",
    "    print(' '.join(words[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df7f485-7c02-48fc-8dde-9317eb2463be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_ngrams(ngram_counts, ngram_label, book_title, top_ngrams=10):\n",
    "    # Sliding window through the text based on the size and to extract the consecutive tokens\n",
    "    top_items = sorted(ngram_counts.items(), key=lambda x: x[1], reverse=True)[:top_ngrams]\n",
    "    \n",
    "    print(f\"\\nTop {top_ngrams} {ngram_label} in {book_title}:\")\n",
    "    for ngram, frequency in top_items:\n",
    "        print(f\"  {ngram}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb294b7-251a-4c46-b10a-2628ec85e46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 trigrams in David_Goulson:\n",
      "  ('one', 'of', 'the'): 5\n",
      "  ('that', 'glyphosate', 'was'): 4\n",
      "  ('the', 'effects', 'of'): 3\n",
      "  ('the', 'number', 'of'): 3\n",
      "  ('that', 'we', 'are'): 3\n",
      "  ('there', 'is', 'a'): 3\n",
      "  ('while', 'the', 'EPA'): 3\n",
      "  ('the', 'safety', 'of'): 3\n",
      "  ('in', 'favour', 'of'): 3\n",
      "  ('non-Hodgkin’s', 'lymphoma', 'after'): 3\n",
      "\n",
      "Top 10 trigrams in Walden:\n",
      "  ('I', 'did', 'not'): 7\n",
      "  ('of', 'the', 'pond,'): 5\n",
      "  ('when', 'he', 'came'): 5\n",
      "  ('that', 'it', 'was'): 4\n",
      "  ('in', 'the', 'woods,'): 4\n",
      "  ('that', 'I', 'could'): 3\n",
      "  ('to', 'see', 'the'): 3\n",
      "  ('I', 'do', 'not'): 3\n",
      "  ('if', 'I', 'had'): 3\n",
      "  ('part', 'of', 'the'): 3\n",
      "\n",
      "Top 10 trigrams in Tropical Nature, and Other Essays:\n",
      "  ('by', 'Alfred', 'Russel'): 4\n",
      "  ('Alfred', 'Russel', 'Wallace'): 4\n",
      "  ('Tropical', 'nature,', 'and'): 3\n",
      "  ('nature,', 'and', 'other'): 3\n",
      "  ('and', 'other', 'essays'): 3\n",
      "  ('other', 'essays', 'by'): 2\n",
      "  ('essays', 'by', 'Alfred'): 2\n",
      "  ('1.2', 'MB', 'EPUB'): 2\n",
      "  ('--', 'The', 'colours'): 2\n",
      "  ('The', 'colours', 'of'): 2\n",
      "\n",
      "Top 10 trigrams in Alan_Weisman:\n",
      "  ('Plymouth', 'marine', 'biologist'): 3\n",
      "  ('he', 'decided', 'to'): 2\n",
      "  ('olive', 'and', 'carob'): 2\n",
      "  ('/', 'THE', 'WORLD'): 2\n",
      "  ('THE', 'WORLD', 'WITHOUT'): 2\n",
      "  ('WORLD', 'WITHOUT', 'US'): 2\n",
      "  ('hadn’t', 'expected', 'to'): 2\n",
      "  ('expected', 'to', 'see'): 2\n",
      "  ('a', 'Turkish', 'Cypriot'): 2\n",
      "  ('when', 'the', 'troubles'): 2\n",
      "\n",
      "Top 10 trigrams in African Nature Notes and Reminiscences:\n",
      "  ('the', 'influence', 'of'): 13\n",
      "  ('the', 'coloration', 'of'): 7\n",
      "  ('coloration', 'of', 'the'): 5\n",
      "  ('mammals,', 'birds,', 'reptiles,'): 5\n",
      "  ('birds,', 'reptiles,', 'and'): 5\n",
      "  ('colour', 'of', 'the'): 5\n",
      "  ('of', 'the', 'Cape'): 5\n",
      "  ('be', 'seen', 'in'): 4\n",
      "  ('of', 'sexual', 'selection,'): 4\n",
      "  ('seen', 'in', 'the'): 4\n",
      "\n",
      "Top 10 trigrams in Dina_Gilio_Whitaker:\n",
      "  ('Anderson,', 'Tending', 'the'): 6\n",
      "  ('American', 'Indians', 'and'): 5\n",
      "  ('the', 'Navajo', 'Nation'): 4\n",
      "  ('accessed', 'October', '8,'): 4\n",
      "  ('October', '8,', '2018.'): 4\n",
      "  ('the', 'history', 'of'): 4\n",
      "  ('Tending', 'the', 'Wild,'): 4\n",
      "  ('American', 'Indian', 'Quarterly'): 4\n",
      "  ('in', 'Nelson,', 'Original'): 3\n",
      "  ('Nelson,', 'Original', 'Instructions,'): 3\n",
      "\n",
      "Top 10 trigrams in Val_Plumwood:\n",
      "  ('the', 'use', 'of'): 7\n",
      "  ('6.', 'Animals', 'and'): 5\n",
      "  ('Animals', 'and', 'ecology:'): 5\n",
      "  ('and', 'ecology:', 'Towards'): 5\n",
      "  ('ecology:', 'Towards', 'a'): 5\n",
      "  ('Towards', 'a', 'better'): 5\n",
      "  ('a', 'better', 'integration'): 5\n",
      "  ('in', 'order', 'to'): 5\n",
      "  ('The', 'Eye', 'of'): 5\n",
      "  ('Eye', 'of', 'the'): 5\n",
      "\n",
      "Top 10 trigrams in Jane_Goodall:\n",
      "  ('more', 'and', 'more'): 4\n",
      "  ('a', 'lot', 'of'): 4\n",
      "  ('one', 'of', 'the'): 4\n",
      "  ('the', 'rest', 'of'): 3\n",
      "  ('the', 'Tanzanian', 'field'): 3\n",
      "  ('I', 'have', 'known'): 3\n",
      "  ('Photograph', 'by', 'Hugo'): 3\n",
      "  ('by', 'Hugo', 'van'): 3\n",
      "  ('©', 'National', 'Geographic'): 3\n",
      "  ('National', 'Geographic', 'Society.'): 3\n",
      "\n",
      "Top 10 trigrams in Amy Godine:\n",
      "  ('the', 'Black', 'Woods'): 7\n",
      "  ('.', '.', '.'): 7\n",
      "  ('of', 'the', 'Black'): 3\n",
      "  ('the', 'North', 'Star,'): 3\n",
      "  ('THE', 'SECOND', 'WAVE'): 3\n",
      "  ('turned', 'out', 'to'): 2\n",
      "  ('to', 'let', 'them'): 2\n",
      "  ('had', 'never', 'been'): 2\n",
      "  ('when', 'he', 'was'): 2\n",
      "  ('thanks', 'to', '“the'): 2\n",
      "\n",
      "Top 10 trigrams in Greta_Thunberg:\n",
      "  ('for', 'the', 'climate'): 6\n",
      "  ('If', 'our', 'house'): 6\n",
      "  ('our', 'house', 'was'): 6\n",
      "  ('house', 'was', 'falling'): 6\n",
      "  ('to', 'listen', 'to'): 5\n",
      "  ('that', 'we', 'are'): 5\n",
      "  ('We', 'live', 'in'): 5\n",
      "  ('live', 'in', 'a'): 5\n",
      "  ('in', 'a', 'strange'): 5\n",
      "  ('want', 'you', 'to'): 4\n"
     ]
    }
   ],
   "source": [
    "for author_name, author_data in final_balanced_data.items():\n",
    "    words = author_data['words']\n",
    "    title = author_data['title']\n",
    "    \n",
    "    # Calculate n-grams, trigrams\n",
    "    from collections import Counter\n",
    "    trigrams = []\n",
    "    for i in range(len(words) - 2):\n",
    "        trigrams.append((words[i], words[i+1], words[i+2]))\n",
    "    \n",
    "    trigram_counts = Counter(trigrams)\n",
    "    \n",
    "    print_top_ngrams(trigram_counts, \"trigrams\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995e019-cb5e-4844-9846-7b7a2761a598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
