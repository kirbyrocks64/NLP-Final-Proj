{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "587fdcb3-05d4-40f3-ad03-72c76ba754ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "txt_files = [\n",
    "    \"Alan_Weisman conv.txt\",\n",
    "    \"Amy Godine conv.txt\",\n",
    "    \"Anne_Therese_Gennari conv.txt\",\n",
    "    \"Barbara_Kingsolver conv.txt\",\n",
    "    \"Camille_T_Dungy conv.txt\",\n",
    "    \"David_Goulson conv.txt\",\n",
    "    \"Dina_Gilio_Whitaker conv.txt\",\n",
    "    \"Greta_Thunberg conv.txt\",\n",
    "    \"Jane_Goodall conv.txt\",\n",
    "    \"Rachel_Carson conv.txt\",\n",
    "    \"Val_Plumwood conv.txt\",\n",
    "    \"_OceanofPDF.com_Braiding_Sweetgrass_-_Robin_Wall_Kimmerer conv.txt\"\n",
    "]\n",
    "\n",
    "guten_dict = {\n",
    "    \"https://www.gutenberg.org/files/17748/17748-h/17748-h.htm\": {\n",
    "        \"title\": \"The Extermination of the American Bison\",\n",
    "        \"author\": \"William T. Hornaday\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/files/205/205-h/205-h.htm\": {\n",
    "        \"title\": \"Walden\", \n",
    "        \"author\": \"Henry David Thoreau\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/49270/pg49270-images.html\": {\n",
    "        \"title\": \"African Nature Notes and Reminiscences\",\n",
    "        \"author\": \"Frederick Courteney Selous\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/66546/pg66546-images.html\": {\n",
    "        \"title\": \"The Ivory King: A Popular History of the Elephant and Its Allies\",\n",
    "        \"author\": \"Charles Fredrick Holde\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/ebooks/73563\": {\n",
    "        \"title\": \"Tropical Nature, and Other Essays\", \n",
    "        \"author\": \"Alfred Russel Wallace\"\n",
    "    },\n",
    "    \"https://www.gutenberg.org/cache/epub/44764/pg44764-images.html\": {\n",
    "        \"title\": \"California: The Land of the Sun\",\n",
    "        \"author\": \"Mary Austin\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "author_genders = {\n",
    "    # Local file authors\n",
    "    \"Alan_Weisman\": \"M\",\n",
    "    \"Amy Godine\": \"F\",\n",
    "    \"Anne_Therese_Gennari\": \"F\",\n",
    "    \"Barbara_Kingsolver\": \"F\",\n",
    "    \"Camille_T_Dungy\": \"F\", \n",
    "    \"David_Goulson\": \"M\",\n",
    "    \"Dina_Gilio_Whitaker\": \"F\",\n",
    "    \"Greta_Thunberg\": \"F\",\n",
    "    \"Jane_Goodall\": \"F\",\n",
    "    \"Rachel_Carson\": \"F\",\n",
    "    \"Val_Plumwood\": \"F\",\n",
    "    \"_Robin_Wall_Kimmerer\": \"F\",\n",
    "    \n",
    "    # Gutenberg authors\n",
    "    \"William T. Hornaday\": \"M\",\n",
    "    \"Henry David Thoreau\": \"M\",\n",
    "    \"Frederick Courteney Selous\": \"M\", \n",
    "    \"Charles Fredrick Holde\": \"M\",\n",
    "    \"Alfred Russel Wallace\": \"M\",\n",
    "    \"Mary Austin\": \"F\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f58209-221f-4b0c-9f91-ca58891deee1",
   "metadata": {},
   "source": [
    "Gutenberg Cleaner:\n",
    "\n",
    "https://github.com/kiasar/gutenberg_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f095b61-fe0c-4176-a9ae-e1b7a11d3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gutenberg_cleaner in /opt/anaconda3/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from gutenberg_cleaner) (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk->gutenberg_cleaner) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gutenberg_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "551e9ea1-5438-4d17-bd57-4f204b999997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenberg_cleaner import simple_cleaner, super_cleaner\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c4e9242-f570-4874-b00c-4ccdff2fa39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cleaner(text):\n",
    "# removes excessive whitespace, keeps punctuation and sentences\n",
    "\n",
    "    # Replace multiple spaces/tabs with single space\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # remove common file header artifacts if they appear at the start\n",
    "    lines = text.split('\\n')\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        # Skip lines that are too short and look like metadata\n",
    "        if len(line.strip()) < 5 and any(keyword in line.lower() for keyword in ['page', 'chapter', 'copyright']):\n",
    "            continue\n",
    "        filtered_lines.append(line.strip())\n",
    "    \n",
    "    return ' '.join(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2d855c8-e3c0-4857-b0ef-c6bd609aed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping The Extermination of the American Bison: only 0 words after filtering\n",
      "Skipping The Ivory King: A Popular History of the Elephant and Its Allies: only 0 words after filtering\n",
      "Skipping California: The Land of the Sun: only 0 words after filtering\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store final results\n",
    "final_dictionary = {}\n",
    "\n",
    "\n",
    "# Process local files \n",
    "for text_file in txt_files:\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Use simple_cleaner local files, might be too harsh for local girlies but we'll see\n",
    "    filtered_content = local_cleaner(content)\n",
    "    \n",
    "    words = filtered_content.split()\n",
    "    # Skip files with 0 or 1 words after filtering\n",
    "    if len(words) <= 1:\n",
    "        print(f\"Skipping {text_file}: only {len(words)} words after filtering\")\n",
    "        continue\n",
    "\n",
    "    author_name = text_file.split(\" conv.txt\")[0]\n",
    "    gender = author_genders.get(author_name, \"Unknown\")\n",
    "\n",
    "    final_dictionary[author_name] = {\n",
    "        \"title\": text_file.replace(\" conv.txt\", \"\"),\n",
    "        \"author\": author_name,\n",
    "        \"words\": text_selection,\n",
    "        \"gender\": gender,\n",
    "        \"word_count\": len(text_selection)\n",
    "    }\n",
    "\n",
    "# Process Gutenberg books\n",
    "for url, meta in guten_dict.items():\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    html = resp.text\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag in soup(['script', 'style', 'header', 'footer', 'nav']):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    clean_text = \" \".join(text.split())\n",
    "\n",
    "    # Just removes lines that are part of the Project Gutenberg header or footer\n",
    "    # Doesnt go deeply in the text to remove other things like titles or footnotes or etc\n",
    "    # return: str of the book without the lines that are part of the Project Gutenberg header and footer\n",
    "    cleaned_text = simple_cleaner(clean_text)  # Basic cleaning\n",
    "    # OR for more aggressive cleaning:\n",
    "    # cleaned_text = super_cleaner(clean_text, min_token=10, max_token=500)\n",
    "    \n",
    "    words = cleaned_text.split()\n",
    "\n",
    "    # Skip files with 0 or 1 words after filtering\n",
    "    if len(words) <= 1:\n",
    "        print(f\"Skipping {meta['title']}: only {len(words)} words after filtering\")\n",
    "        continue\n",
    "\n",
    "    author_name = meta[\"author\"]\n",
    "    gender = author_genders.get(author_name, \"Unknown\")\n",
    "\n",
    "    final_dictionary[author_name] = {\n",
    "        \"title\": meta[\"title\"],\n",
    "        \"author\": author_name,\n",
    "        \"words\": text_selection,\n",
    "        \"gender\": gender,\n",
    "        \"word_count\": len(text_selection)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c168400d-c7b9-4d56-9b33-7d4b4920781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors after processing: 15\n",
      "Valid male authors: 5, Valid female authors: 9\n",
      "Total authors in balanced dataset: 10\n",
      "Male authors: 5, Female authors: 5\n",
      "Final balanced dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total authors after processing: {len(final_dictionary)}\")\n",
    "\n",
    "# Balance genders - only include authors with word_count > 1\n",
    "valid_authors = {author: data for author, data in final_dictionary.items() if data['word_count'] > 1}\n",
    "\n",
    "male_authors = [author for author, data in valid_authors.items() if data['gender'] == 'M']\n",
    "female_authors = [author for author, data in valid_authors.items() if data['gender'] == 'F']\n",
    "\n",
    "print(f\"Valid male authors: {len(male_authors)}, Valid female authors: {len(female_authors)}\")\n",
    "\n",
    "if len(male_authors) == 0 or len(female_authors) == 0:\n",
    "    balanced_data = valid_authors\n",
    "else:\n",
    "    min_count = min(len(male_authors), len(female_authors))\n",
    "\n",
    "    balanced_male = np.random.choice(male_authors, min_count, replace=False)\n",
    "    balanced_female = np.random.choice(female_authors, min_count, replace=False)\n",
    "\n",
    "    balanced_authors = list(balanced_male) + list(balanced_female)\n",
    "    balanced_data = {author: valid_authors[author] for author in balanced_authors}\n",
    "\n",
    "    print(f\"Total authors in balanced dataset: {len(balanced_data)}\")\n",
    "    print(f\"Male authors: {len(balanced_male)}, Female authors: {len(balanced_female)}\")\n",
    "\n",
    "# Final check - remove any authors with 0 or 1 words from balanced_data (just to be safe)\n",
    "final_balanced_data = {author: data for author, data in balanced_data.items() if data['word_count'] > 1}\n",
    "print(f\"Final balanced dataset size: {len(final_balanced_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c55ebc91-4fdb-4434-b31e-b75a8a5c0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "African Nature Notes and Reminiscences - First 10 words:\n",
      "that would not quietly withdraw, satisfied with the mercurial dose\n",
      "\n",
      "David_Goulson - First 10 words:\n",
      "‘convergent evolution’, whereby two unrelated creatures evolve to resemble one\n",
      "\n",
      "Alan_Weisman - First 10 words:\n",
      "ST. MARTIN'S PRESS NEW YORK THOMAS DUNNE BOOKS. An imprint\n",
      "\n",
      "Walden - First 10 words:\n",
      "was likely to hold together much longer, I was let\n",
      "\n",
      "Tropical Nature, and Other Essays - First 10 words:\n",
      "Tropical nature, and other essays by Alfred Russel Wallace |\n",
      "\n",
      "Val_Plumwood - First 10 words:\n",
      "subject’s universe is like the person-as-the-walled-moated-castle-town. It is under constant\n",
      "\n",
      "Anne_Therese_Gennari - First 10 words:\n",
      "influence gives us the power to help others and shift\n",
      "\n",
      "Rachel_Carson - First 10 words:\n",
      "the time to flare again into activity when spring awakens\n",
      "\n",
      "Barbara_Kingsolver - First 10 words:\n",
      "who winced, both at her foul language and at her\n",
      "\n",
      "Dina_Gilio_Whitaker - First 10 words:\n",
      "country, especially when accompanied by a lack of disclosure of\n"
     ]
    }
   ],
   "source": [
    "for author_name, author_data in final_balanced_data.items():\n",
    "    words = author_data['words']\n",
    "    title = author_data['title']\n",
    "    \n",
    "    # Print first 10 words to see what's getting through\n",
    "    print(f\"\\n{title} - First 10 words:\")\n",
    "    print(' '.join(words[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7df7f485-7c02-48fc-8dde-9317eb2463be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_ngrams(ngram_counts, ngram_label, book_title, top_ngrams=10):\n",
    "    # Sliding window through the text based on the size and to extract the consecutive tokens\n",
    "    top_items = sorted(ngram_counts.items(), key=lambda x: x[1], reverse=True)[:top_ngrams]\n",
    "    \n",
    "    print(f\"\\nTop {top_ngrams} {ngram_label} in {book_title}:\")\n",
    "    for ngram, frequency in top_items:\n",
    "        print(f\"  {ngram}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6eb294b7-251a-4c46-b10a-2628ec85e46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 trigrams in African Nature Notes and Reminiscences:\n",
      "  ('a', 'black', 'rhinoceros'): 11\n",
      "  ('the', 'black', 'rhinoceros'): 11\n",
      "  ('of', 'the', 'black'): 9\n",
      "  ('black', 'rhinoceros', 'in'): 7\n",
      "  ('by', 'a', 'black'): 5\n",
      "  ('of', 'both', 'the'): 4\n",
      "  ('both', 'the', 'black'): 4\n",
      "  ('the', 'black', 'and'): 4\n",
      "  ('black', 'and', 'the'): 4\n",
      "  ('and', 'the', 'white'): 4\n",
      "\n",
      "Top 10 trigrams in David_Goulson:\n",
      "  ('to', 'ensure', 'that'): 5\n",
      "  ('for', 'national', 'government'): 4\n",
      "  ('Actions', 'for', 'all'): 4\n",
      "  ('In', 'the', 'UK,'): 4\n",
      "  ('of', 'pesticides', 'in'): 4\n",
      "  ('fruit', 'and', 'veg.'): 3\n",
      "  ('be', 'used', 'to'): 3\n",
      "  ('Actions', 'for', 'national'): 3\n",
      "  ('use', 'of', 'pesticides'): 3\n",
      "  ('per', 'cent', 'of'): 3\n",
      "\n",
      "Top 10 trigrams in Alan_Weisman:\n",
      "  ('THE', 'WORLD', 'WITHOUT'): 2\n",
      "  ('of', 'this', 'book'): 2\n",
      "  ('shore', 'of', 'the'): 2\n",
      "  ('the', 'Green', 'Line'): 2\n",
      "  ('Greeks', 'to', 'the'): 2\n",
      "  ('When', 'the', 'war'): 2\n",
      "  ('by', 'Greek', 'Cypriots'): 2\n",
      "  ('side', 'of', 'the'): 2\n",
      "  ('the', 'size', 'of'): 2\n",
      "  ('he', 'decided', 'to'): 2\n",
      "\n",
      "Top 10 trigrams in Walden:\n",
      "  ('Â', 'Â', 'Â'): 28\n",
      "  ('It', 'is', 'a'): 5\n",
      "  ('from', 'time', 'to'): 4\n",
      "  ('the', 'color', 'of'): 4\n",
      "  ('to', 'the', 'woods'): 3\n",
      "  ('in', 'the', 'woods,'): 3\n",
      "  ('when', 'it', 'was'): 3\n",
      "  ('way', 'to', 'the'): 3\n",
      "  ('close', 'at', 'hand.'): 3\n",
      "  ('rods', 'from', 'the'): 3\n",
      "\n",
      "Top 10 trigrams in Tropical Nature, and Other Essays:\n",
      "  ('by', 'Alfred', 'Russel'): 4\n",
      "  ('Alfred', 'Russel', 'Wallace'): 4\n",
      "  ('Tropical', 'nature,', 'and'): 3\n",
      "  ('nature,', 'and', 'other'): 3\n",
      "  ('and', 'other', 'essays'): 3\n",
      "  ('other', 'essays', 'by'): 2\n",
      "  ('essays', 'by', 'Alfred'): 2\n",
      "  ('1.2', 'MB', 'EPUB'): 2\n",
      "  ('--', 'The', 'colours'): 2\n",
      "  ('The', 'colours', 'of'): 2\n",
      "\n",
      "Top 10 trigrams in Val_Plumwood:\n",
      "  ('wisdom', 'of', 'the'): 9\n",
      "  ('of', 'the', 'balanced'): 8\n",
      "  ('The', 'Eye', 'of'): 5\n",
      "  ('Eye', 'of', 'the'): 5\n",
      "  ('of', 'the', 'Crocodile'): 5\n",
      "  ('The', 'wisdom', 'of'): 5\n",
      "  ('the', 'food', 'chain'): 4\n",
      "  ('we', 'have', 'to'): 4\n",
      "  ('3.', 'The', 'wisdom'): 4\n",
      "  ('the', 'balanced', 'rock:'): 4\n",
      "\n",
      "Top 10 trigrams in Anne_Therese_Gennari:\n",
      "  ('I', 'want', 'to'): 7\n",
      "  ('I', 'want', 'you'): 6\n",
      "  ('want', 'you', 'to'): 6\n",
      "  ('we', 'have', 'to'): 5\n",
      "  ('have', 'to', 'do'): 5\n",
      "  ('in', 'the', 'right'): 5\n",
      "  ('I', 'can', 'feel'): 4\n",
      "  ('to', 'slow', 'down'): 4\n",
      "  ('you', 'have', 'to'): 4\n",
      "  ('to', 'do', 'is'): 4\n",
      "\n",
      "Top 10 trigrams in Rachel_Carson:\n",
      "  ('one', 'of', 'the'): 4\n",
      "  ('the', 'end', 'of'): 4\n",
      "  ('parts', 'of', 'the'): 4\n",
      "  ('the', 'United', 'States'): 3\n",
      "  ('all', 'of', 'the'): 3\n",
      "  ('per', 'cent', 'of'): 3\n",
      "  ('of', 'the', 'most'): 3\n",
      "  ('much', 'of', 'the'): 3\n",
      "  ('of', 'the', 'insect'): 3\n",
      "  ('enemies', 'of', 'the'): 3\n",
      "\n",
      "Top 10 trigrams in Barbara_Kingsolver:\n",
      "  ('B', 'A', 'R'): 12\n",
      "  ('{', 'P', 'r'): 7\n",
      "  ('P', 'r', 'o'): 7\n",
      "  ('r', 'o', 'd'): 7\n",
      "  ('o', 'd', 'i'): 7\n",
      "  ('d', 'i', 'g'): 7\n",
      "  ('i', 'g', 'a'): 7\n",
      "  ('g', 'a', 'l'): 7\n",
      "  ('a', 'l', 'S'): 7\n",
      "  ('l', 'S', 'u'): 7\n",
      "\n",
      "Top 10 trigrams in Dina_Gilio_Whitaker:\n",
      "  ('Indian', 'Health', 'Service'): 3\n",
      "  ('lands', 'of', 'the'): 3\n",
      "  ('the', 'United', 'States’'): 3\n",
      "  ('of', 'the', 'US'): 3\n",
      "  ('the', 'same', 'time,'): 3\n",
      "  ('one', 'of', 'the'): 3\n",
      "  ('adjacent', 'to', 'the'): 2\n",
      "  ('in', 'Washington', 'State,'): 2\n",
      "  ('the', 'Indian', 'Health'): 2\n",
      "  ('uranium', 'mining', 'and'): 2\n"
     ]
    }
   ],
   "source": [
    "for author_name, author_data in final_balanced_data.items():\n",
    "    words = author_data['words']\n",
    "    title = author_data['title']\n",
    "    \n",
    "    # Calculate n-grams, trigrams\n",
    "    from collections import Counter\n",
    "    trigrams = []\n",
    "    for i in range(len(words) - 2):\n",
    "        trigrams.append((words[i], words[i+1], words[i+2]))\n",
    "    \n",
    "    trigram_counts = Counter(trigrams)\n",
    "    \n",
    "    print_top_ngrams(trigram_counts, \"trigrams\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ab285-0124-4862-8326-19a3f7b79b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
