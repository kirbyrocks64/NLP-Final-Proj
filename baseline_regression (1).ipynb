{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11831412-2829-4b48-aef3-53609b1fa0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (12, 3)\n",
      "Number of unique authors: 12\n",
      "Total samples: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"NLPCleanData.csv\")\n",
    "print(f\"CSV shape: {df.shape}\")\n",
    "print(f\"Number of unique authors: {df['Author'].nunique()}\")\n",
    "print(f\"Total samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826a15c2-d520-4198-9b15-860ec57f0a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred Russel Wallace</td>\n",
       "      <td>Male</td>\n",
       "      <td>solar heat and light, as entirely unsupported ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Godine</td>\n",
       "      <td>Female</td>\n",
       "      <td>men fought slavery. Its centrality in their li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles Fredrick Holder</td>\n",
       "      <td>Male</td>\n",
       "      <td>houses, or any object that excited its ire, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Goulson</td>\n",
       "      <td>Male</td>\n",
       "      <td>frame as a contender to explain insect decline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frederick Courteney Selous</td>\n",
       "      <td>Male</td>\n",
       "      <td>there seems every reason to believe have died ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greta Thunberg</td>\n",
       "      <td>Female</td>\n",
       "      <td>to that challenge. But I want to ask you all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry David Thoreau</td>\n",
       "      <td>Male</td>\n",
       "      <td>part of the fruit is lost with the bloom which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jane Goodall</td>\n",
       "      <td>Female</td>\n",
       "      <td>moon. If I heard the coughing grunt of a leopa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rachel Carson</td>\n",
       "      <td>Female</td>\n",
       "      <td>almost nonexistent, until such time as careful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Robin Wall Kimmerer</td>\n",
       "      <td>Female</td>\n",
       "      <td>people. She smiled kindly at him and instructe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Val Plumwood</td>\n",
       "      <td>Female</td>\n",
       "      <td>life, in favour of a distant abstract ideal or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>William T. Hornaday</td>\n",
       "      <td>Male</td>\n",
       "      <td>animal that will rustle the prairies, and not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Author  Gender  \\\n",
       "0        Alfred Russel Wallace    Male   \n",
       "1                   Amy Godine  Female   \n",
       "2      Charles Fredrick Holder    Male   \n",
       "3                David Goulson    Male   \n",
       "4   Frederick Courteney Selous    Male   \n",
       "5               Greta Thunberg  Female   \n",
       "6          Henry David Thoreau    Male   \n",
       "7                 Jane Goodall  Female   \n",
       "8                Rachel Carson  Female   \n",
       "9          Robin Wall Kimmerer  Female   \n",
       "10                Val Plumwood  Female   \n",
       "11         William T. Hornaday    Male   \n",
       "\n",
       "                                               Sample  \n",
       "0   solar heat and light, as entirely unsupported ...  \n",
       "1   men fought slavery. Its centrality in their li...  \n",
       "2   houses, or any object that excited its ire, an...  \n",
       "3   frame as a contender to explain insect decline...  \n",
       "4   there seems every reason to believe have died ...  \n",
       "5   to that challenge. But I want to ask you all t...  \n",
       "6   part of the fruit is lost with the bloom which...  \n",
       "7   moon. If I heard the coughing grunt of a leopa...  \n",
       "8   almost nonexistent, until such time as careful...  \n",
       "9   people. She smiled kindly at him and instructe...  \n",
       "10  life, in favour of a distant abstract ideal or...  \n",
       "11  animal that will rustle the prairies, and not ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597ed470-9906-4b4a-a867-e4207337b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Author  12 non-null     object\n",
      " 1   Gender  12 non-null     object\n",
      " 2   Sample  12 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 420.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464e56f1-45e2-4248-91ee-5da8cd7879a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])  # Adds new column: Male=0, Female=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f543e1-11e3-4b72-b78b-083c2d487443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender encoding mapping:\n",
      "  Female → 0\n",
      "  Male → 1\n",
      "\n",
      "New shape after splitting: (120, 4)\n",
      "Male (0): 60 samples\n",
      "Female (1): 60 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Total Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred Russel Wallace_chunk0</td>\n",
       "      <td>1</td>\n",
       "      <td>solar heat light, entirely unsupported facts. ...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfred Russel Wallace_chunk1</td>\n",
       "      <td>1</td>\n",
       "      <td>pupa exposed soft, semi-transparent condition,...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred Russel Wallace_chunk2</td>\n",
       "      <td>1</td>\n",
       "      <td>peculiar powers change colour adaptation are, ...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred Russel Wallace_chunk3</td>\n",
       "      <td>1</td>\n",
       "      <td>Animals,” (_Contributions Theory Natural Selec...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alfred Russel Wallace_chunk4</td>\n",
       "      <td>1</td>\n",
       "      <td>tint pattern; fly slowly, never attempt concea...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>William T. Hornaday_chunk5</td>\n",
       "      <td>1</td>\n",
       "      <td>herd includes two fine bull calves dropped las...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>William T. Hornaday_chunk6</td>\n",
       "      <td>1</td>\n",
       "      <td>respecting herd, date November 1, 1888: \"The a...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>William T. Hornaday_chunk7</td>\n",
       "      <td>1</td>\n",
       "      <td>D. Nowell, North Platte, Nebraska, $100 pair, ...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>William T. Hornaday_chunk8</td>\n",
       "      <td>1</td>\n",
       "      <td>know precisely were, sad fate buffalo warned t...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>William T. Hornaday_chunk9</td>\n",
       "      <td>1</td>\n",
       "      <td>probabilities are, however, shooting Texas cat...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Author  Gender  \\\n",
       "0    Alfred Russel Wallace_chunk0       1   \n",
       "1    Alfred Russel Wallace_chunk1       1   \n",
       "2    Alfred Russel Wallace_chunk2       1   \n",
       "3    Alfred Russel Wallace_chunk3       1   \n",
       "4    Alfred Russel Wallace_chunk4       1   \n",
       "..                            ...     ...   \n",
       "115    William T. Hornaday_chunk5       1   \n",
       "116    William T. Hornaday_chunk6       1   \n",
       "117    William T. Hornaday_chunk7       1   \n",
       "118    William T. Hornaday_chunk8       1   \n",
       "119    William T. Hornaday_chunk9       1   \n",
       "\n",
       "                                                Sample  Total Words  \n",
       "0    solar heat light, entirely unsupported facts. ...          259  \n",
       "1    pupa exposed soft, semi-transparent condition,...          259  \n",
       "2    peculiar powers change colour adaptation are, ...          259  \n",
       "3    Animals,” (_Contributions Theory Natural Selec...          259  \n",
       "4    tint pattern; fly slowly, never attempt concea...          259  \n",
       "..                                                 ...          ...  \n",
       "115  herd includes two fine bull calves dropped las...          280  \n",
       "116  respecting herd, date November 1, 1888: \"The a...          280  \n",
       "117  D. Nowell, North Platte, Nebraska, $100 pair, ...          280  \n",
       "118  know precisely were, sad fate buffalo warned t...          280  \n",
       "119  probabilities are, however, shooting Texas cat...          288  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you have 5,000 words per author, but only 15 rows total,\n",
    "# then each row must contain ALL 5,000 words for one author\n",
    "# We need to split each row into multiple samples\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if needed, “the”, “of”, and “to”\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df = pd.read_csv(\"NLPCleanData.csv\")\n",
    "\n",
    "# Label encode thhe gener column\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])  # Now Male=0, Female=1\n",
    "\n",
    "print(\"Gender encoding mapping:\")\n",
    "print(f\"  {le.classes_[0]} → 0\")\n",
    "print(f\"  {le.classes_[1]} → 1\")\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = str(text).split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply stopword removal\n",
    "df['Sample'] = df['Sample'].apply(remove_stopwords)\n",
    "\n",
    "# Function to split text into N equal chunks, no overlap\n",
    "def split_into_equal_chunks(text, num_chunks=10):\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    "    \n",
    "    if total_words == 0:\n",
    "        return []\n",
    "    \n",
    "    # Calculate chunk size\n",
    "    chunk_size = max(1, total_words // num_chunks)  # Ensure at least 1 word in each cheinl \n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = start_idx + chunk_size if i < num_chunks - 1 else total_words\n",
    "        \n",
    "        if start_idx < total_words:\n",
    "            chunk = ' '.join(words[start_idx:end_idx])\n",
    "            if chunk.strip():  \n",
    "                chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Process each row to create more samples\n",
    "new_rows = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row['Sample'])\n",
    "    label = row['Gender']  # Now numeric (0 or 1)\n",
    "    author = row['Author']\n",
    "    \n",
    "    # Split into 10 equal chunks, no overlap\n",
    "    chunks = split_into_equal_chunks(text, num_chunks=10)\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        new_rows.append({\n",
    "            'Author': f\"{author}_chunk{chunk_idx}\",\n",
    "            'Gender': label,  # Already numeric 0/1\n",
    "            'Sample': chunk,\n",
    "            'Total Words': len(chunk.split()),\n",
    "        })\n",
    "\n",
    "# Create new DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "print(f\"\\nNew shape after splitting: {new_df.shape}\")\n",
    "print(f\"Male (0): {sum(new_df['Gender'] == 0)} samples\")\n",
    "print(f\"Female (1): {sum(new_df['Gender'] == 1)} samples\")\n",
    "\n",
    "# Save the expanded dataset\n",
    "new_df.to_csv(\"NLPCleanData_Chunky.csv\", index=False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2bfb9d7-7898-4cec-a92c-a041fff5574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Total Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred Russel Wallace_chunk0</td>\n",
       "      <td>1</td>\n",
       "      <td>solar heat light, entirely unsupported facts. ...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfred Russel Wallace_chunk1</td>\n",
       "      <td>1</td>\n",
       "      <td>pupa exposed soft, semi-transparent condition,...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred Russel Wallace_chunk2</td>\n",
       "      <td>1</td>\n",
       "      <td>peculiar powers change colour adaptation are, ...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred Russel Wallace_chunk3</td>\n",
       "      <td>1</td>\n",
       "      <td>Animals,” (_Contributions Theory Natural Selec...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alfred Russel Wallace_chunk4</td>\n",
       "      <td>1</td>\n",
       "      <td>tint pattern; fly slowly, never attempt concea...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>William T. Hornaday_chunk5</td>\n",
       "      <td>1</td>\n",
       "      <td>herd includes two fine bull calves dropped las...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>William T. Hornaday_chunk6</td>\n",
       "      <td>1</td>\n",
       "      <td>respecting herd, date November 1, 1888: \"The a...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>William T. Hornaday_chunk7</td>\n",
       "      <td>1</td>\n",
       "      <td>D. Nowell, North Platte, Nebraska, $100 pair, ...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>William T. Hornaday_chunk8</td>\n",
       "      <td>1</td>\n",
       "      <td>know precisely were, sad fate buffalo warned t...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>William T. Hornaday_chunk9</td>\n",
       "      <td>1</td>\n",
       "      <td>probabilities are, however, shooting Texas cat...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Author  Gender  \\\n",
       "0    Alfred Russel Wallace_chunk0       1   \n",
       "1    Alfred Russel Wallace_chunk1       1   \n",
       "2    Alfred Russel Wallace_chunk2       1   \n",
       "3    Alfred Russel Wallace_chunk3       1   \n",
       "4    Alfred Russel Wallace_chunk4       1   \n",
       "..                            ...     ...   \n",
       "115    William T. Hornaday_chunk5       1   \n",
       "116    William T. Hornaday_chunk6       1   \n",
       "117    William T. Hornaday_chunk7       1   \n",
       "118    William T. Hornaday_chunk8       1   \n",
       "119    William T. Hornaday_chunk9       1   \n",
       "\n",
       "                                                Sample  Total Words  \n",
       "0    solar heat light, entirely unsupported facts. ...          259  \n",
       "1    pupa exposed soft, semi-transparent condition,...          259  \n",
       "2    peculiar powers change colour adaptation are, ...          259  \n",
       "3    Animals,” (_Contributions Theory Natural Selec...          259  \n",
       "4    tint pattern; fly slowly, never attempt concea...          259  \n",
       "..                                                 ...          ...  \n",
       "115  herd includes two fine bull calves dropped las...          280  \n",
       "116  respecting herd, date November 1, 1888: \"The a...          280  \n",
       "117  D. Nowell, North Platte, Nebraska, $100 pair, ...          280  \n",
       "118  know precisely were, sad fate buffalo warned t...          280  \n",
       "119  probabilities are, however, shooting Texas cat...          288  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d4713f-b56f-43b7-92b3-48a17562fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9166666666666666\n",
      "Training accuracy is 0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "new_df['Sample'] = (new_df['Sample'].str.replace(r'[^a-zA-Z\\s]+', '', regex=True).str.lower())\n",
    "\n",
    "X=new_df['Sample']\n",
    "y=new_df['Gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=.2, random_state=1234)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=35,  # best is\n",
    "    ngram_range=(1, 1)  )\n",
    "\n",
    "Xtrain = vectorizer.fit_transform(X_train).toarray()\n",
    "Xtest = vectorizer.transform(X_test).toarray()\n",
    "Ytrain = np.array(y_train)\n",
    "Ytest = np.array(y_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "log=LogisticRegression()\n",
    "model=log.fit(Xtrain,Ytrain)\n",
    "ypred=model.predict(Xtest)\n",
    "acc=accuracy_score(Ytest,ypred)\n",
    "tacc=model.score(Xtrain,Ytrain)\n",
    "\n",
    "print(f\"Accuracy is {acc}\")\n",
    "print(f\"Training accuracy is {tacc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b6e389-3545-4ae0-a71a-ac7862b68cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13725147, 0.        , 0.        , 0.        , 0.52809364,\n",
       "        0.        , 0.19279136, 0.        , 0.16151291, 0.        ,\n",
       "        0.38558271, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.13725147, 0.16151291, 0.        , 0.        , 0.38558271,\n",
       "        0.17603121, 0.17603121, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.48453874],\n",
       "       [0.12121351, 0.34052702, 0.34052702, 0.        , 0.1554618 ,\n",
       "        0.1554618 , 0.        , 0.        , 0.28527996, 0.        ,\n",
       "        0.        , 0.46638541, 0.        , 0.        , 0.17026351,\n",
       "        0.        , 0.14263998, 0.1554618 , 0.17026351, 0.        ,\n",
       "        0.1554618 , 0.1554618 , 0.17026351, 0.        , 0.34052702,\n",
       "        0.17026351, 0.28527996],\n",
       "       [0.        , 0.        , 0.        , 0.2910455 , 0.13287186,\n",
       "        0.13287186, 0.14552275, 0.14552275, 0.12191316, 0.14552275,\n",
       "        0.        , 0.        , 0.        , 0.14552275, 0.72761374,\n",
       "        0.        , 0.36573948, 0.        , 0.14552275, 0.14552275,\n",
       "        0.        , 0.        , 0.        , 0.13287186, 0.14552275,\n",
       "        0.14552275, 0.12191316],\n",
       "       [0.        , 0.35812198, 0.17906099, 0.35812198, 0.        ,\n",
       "        0.32698897, 0.        , 0.        , 0.15001016, 0.        ,\n",
       "        0.17906099, 0.16349448, 0.16349448, 0.17906099, 0.17906099,\n",
       "        0.12747659, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49048345, 0.16349448, 0.17906099, 0.16349448, 0.        ,\n",
       "        0.        , 0.30002032],\n",
       "       [0.13853949, 0.        , 0.19460058, 0.19460058, 0.17768315,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.19460058,\n",
       "        0.38920116, 0.3553663 , 0.        , 0.        , 0.        ,\n",
       "        0.27707897, 0.        , 0.        , 0.19460058, 0.19460058,\n",
       "        0.3553663 , 0.17768315, 0.19460058, 0.17768315, 0.        ,\n",
       "        0.38920116, 0.16302861],\n",
       "       [0.12108077, 0.        , 0.        , 0.        , 0.15529156,\n",
       "        0.15529156, 0.        , 0.        , 0.        , 0.17007706,\n",
       "        0.        , 0.15529156, 0.        , 0.17007706, 0.        ,\n",
       "        0.24216154, 0.14248378, 0.15529156, 0.17007706, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.85038528,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.23517311, 0.        , 0.        , 0.        ,\n",
       "        0.21472855, 0.        , 0.23517311, 0.19701866, 0.        ,\n",
       "        0.        , 0.42945709, 0.42945709, 0.        , 0.47034622,\n",
       "        0.16742377, 0.        , 0.21472855, 0.        , 0.        ,\n",
       "        0.21472855, 0.        , 0.23517311, 0.        , 0.        ,\n",
       "        0.        , 0.19701866],\n",
       "       [0.11727725, 0.16473441, 0.16473441, 0.        , 0.30082675,\n",
       "        0.        , 0.        , 0.16473441, 0.        , 0.16473441,\n",
       "        0.82367207, 0.        , 0.15041337, 0.16473441, 0.        ,\n",
       "        0.11727725, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15041337, 0.        , 0.15041337, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.41986072, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.19658689, 0.        , 0.        , 0.19658689,\n",
       "        0.19658689, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.13995357, 0.32938532, 0.        , 0.        , 0.58976066,\n",
       "        0.        , 0.        , 0.19658689, 0.        , 0.39317378,\n",
       "        0.19658689, 0.        ],\n",
       "       [0.12621521, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.70915674, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16187671, 0.        , 0.53186756,\n",
       "        0.        , 0.29705163, 0.16187671, 0.        , 0.17728919,\n",
       "        0.        , 0.        , 0.        , 0.16187671, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.40398841, 0.        , 0.        , 0.18915517, 0.        ,\n",
       "        0.17271113, 0.        , 0.18915517, 0.15846666, 0.        ,\n",
       "        0.        , 0.34542226, 0.17271113, 0.18915517, 0.        ,\n",
       "        0.1346628 , 0.31693332, 0.17271113, 0.        , 0.        ,\n",
       "        0.17271113, 0.        , 0.        , 0.        , 0.5674655 ,\n",
       "        0.        , 0.15846666],\n",
       "       [0.21646404, 0.30405791, 0.15202896, 0.15202896, 0.        ,\n",
       "        0.        , 0.30405791, 0.15202896, 0.1273638 , 0.        ,\n",
       "        0.        , 0.        , 0.13881246, 0.        , 0.        ,\n",
       "        0.21646404, 0.        , 0.13881246, 0.30405791, 0.        ,\n",
       "        0.        , 0.41643737, 0.        , 0.55524982, 0.        ,\n",
       "        0.15202896, 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
